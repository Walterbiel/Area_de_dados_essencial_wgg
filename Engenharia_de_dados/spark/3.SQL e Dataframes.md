
# Spark SQL e DataFrame API ‚Äî Guia Extensivo com Explica√ß√µes e 50 Exerc√≠cios Resolvidos

Este material oferece um estudo completo e profundo sobre **PySpark DataFrame API** e **Spark SQL**. Inclui:

- ‚úÖ Conceitos fundamentais
- ‚úÖ Explica√ß√µes de fun√ß√µes com par√¢metros e uso
- ‚úÖ 50 exerc√≠cios resolvidos (25 DataFrame API + 25 SQL)
- ‚úÖ Coment√°rios detalhados em cada linha de c√≥digo

---

## üöÄ 1. Inicializa√ß√£o

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, expr, upper, lower

spark = SparkSession.builder.appName("SparkSQL_Explicado").getOrCreate()
```

### Explica√ß√µes:
- `SparkSession.builder`: ponto de entrada para PySpark.
- `.appName("nome")`: nome da aplica√ß√£o (aparece no Spark UI).
- `.getOrCreate()`: cria uma nova sess√£o ou reutiliza uma existente.

---

## üß± 2. Criando um DataFrame

```python
data = [("Ana", 28, "SP"), ("Bruno", 33, "RJ")]
columns = ["nome", "idade", "estado"]
df = spark.createDataFrame(data, schema=columns)
df.createOrReplaceTempView("pessoas")
```

### Explica√ß√µes:
- `createDataFrame(data, schema)`: cria um DataFrame a partir de uma lista de tuplas.
- `createOrReplaceTempView()`: cria uma view tempor√°ria para consultas SQL.

---

## üß™ 3. Fun√ß√µes comuns da DataFrame API (com explica√ß√µes)

```python
df.select("nome", "idade").show()
# Projeta colunas espec√≠ficas.
```

```python
df.filter(col("idade") > 30).show()
# Filtra linhas conforme condi√ß√£o com col().
```

```python
df.withColumn("idade_plus_10", col("idade") + 10).show()
# Cria nova coluna com base em express√£o.
```

```python
df.orderBy(col("idade").desc()).show()
# Ordena por idade decrescente.
```

```python
df.groupBy("estado").agg({"idade": "avg"}).show()
# Agrupa por estado e calcula m√©dia de idade.
```

```python
df.selectExpr("upper(nome) as nome_maiusculo").show()
# Usa express√£o SQL para converter para mai√∫sculo.
```

```python
df.drop("estado").show()
# Remove coluna 'estado'.
```

```python
df.distinct().show()
# Remove linhas duplicadas.
```

```python
df.withColumn("faixa", expr("CASE WHEN idade < 25 THEN 'jovem' WHEN idade <= 35 THEN 'adulto' ELSE 's√™nior' END")).show()
# Cria coluna categ√≥rica com l√≥gica condicional (CASE WHEN).
```

```python
df.cache()
# Persiste o DataFrame em mem√≥ria ap√≥s a primeira a√ß√£o.
```

```python
df.sample(0.5, seed=123).show()
# Retorna amostra aleat√≥ria de 50% dos dados.
```

---

## üß† 4. Spark SQL (explica√ß√µes por comando)

```python
spark.sql("SELECT * FROM pessoas").show()
# Seleciona todos os dados da view.
```

```python
spark.sql("SELECT nome, idade FROM pessoas WHERE idade > 30").show()
# Filtro com condi√ß√£o.
```

```python
spark.sql("SELECT estado, COUNT(*) FROM pessoas GROUP BY estado").show()
# Agrega√ß√£o por estado.
```

```python
spark.sql("SELECT AVG(idade) FROM pessoas").show()
# M√©dia geral.
```

```python
spark.sql("SELECT DISTINCT estado FROM pessoas").show()
# Estados √∫nicos.
```

```python
spark.sql("SELECT nome, idade * 2 AS idade_dobrada FROM pessoas").show()
# Multiplica√ß√£o com alias.
```

```python
spark.sql("""
SELECT nome,
  CASE
    WHEN idade < 25 THEN 'jovem'
    WHEN idade <= 35 THEN 'adulto'
    ELSE 's√™nior'
  END as faixa
FROM pessoas
""").show()
# Categoriza√ß√£o com CASE WHEN.
```

```python
spark.sql("SELECT * FROM pessoas ORDER BY estado, idade DESC").show()
# Ordena√ß√£o m√∫ltipla.
```

```python
spark.sql("SELECT * FROM pessoas WHERE estado IN ('SP', 'RJ')").show()
# Filtro com m√∫ltiplos valores.
```

```python
spark.sql("""
SELECT * FROM pessoas
WHERE idade > (SELECT AVG(idade) FROM pessoas)
""").show()
# Subquery: pessoas com idade acima da m√©dia.
```

---

## ‚úÖ Tabela-resumo de fun√ß√µes √∫teis

| Fun√ß√£o | Uso |
|--------|-----|
| `col("nome")` | Acessar coluna |
| `expr()` | Express√£o SQL dentro do PySpark |
| `selectExpr()` | SQL direto no select |
| `groupBy().agg()` | Agrega√ß√µes |
| `orderBy()` | Ordenar |
| `drop()` | Remover colunas |
| `withColumn()` | Criar/alterar colunas |
| `isNull()` | Filtros de nulos |
| `cache()` | Persistir em mem√≥ria |
| `sample()` | Amostragem |

---

Com isso, voc√™ tem as principais ferramentas para interpretar, transformar e manipular dados estruturados com Spark de forma eficiente e otimizada.

## üìå In√≠cio: Criando um DataFrame base

```python
from pyspark.sql import SparkSession
from pyspark.sql.functions import col, expr, upper, lower

spark = SparkSession.builder.appName("SparkSQL_Exercicios").getOrCreate()

data = [
    ("Ana", 28, "SP"),
    ("Bruno", 33, "RJ"),
    ("Carlos", 19, "MG"),
    ("Daniela", 40, "SP"),
    ("Eduardo", 25, "RJ"),
    ("Felipe", 19, "MG"),
    ("Gabriela", 31, "SP")
]
columns = ["nome", "idade", "estado"]
df = spark.createDataFrame(data, schema=columns)
df.createOrReplaceTempView("pessoas")
```

---

# üìò Parte 1 ‚Äì 25 Exerc√≠cios com DataFrame API

```python
# 1. Mostrar dados
df.show()

# 2. Mostrar esquema
df.printSchema()

# 3. Selecionar colunas
df.select("nome", "idade").show()

# 4. Adicionar 2 anos √† idade
df.select("nome", (col("idade") + 2).alias("idade_mais2")).show()

# 5. Filtrar idade > 30
df.filter(col("idade") > 30).show()

# 6. Filtrar estado = 'SP'
df.filter(col("estado") == "SP").show()

# 7. Ordenar por idade decrescente
df.orderBy(col("idade").desc()).show()

# 8. Agrupar por estado e contar
df.groupBy("estado").count().show()

# 9. M√©dia de idade por estado
df.groupBy("estado").avg("idade").show()

# 10. Criar nova coluna idade*2
df.withColumn("idade_dobrada", col("idade") * 2).show()

# 11. Remover coluna 'estado'
df.drop("estado").show()

# 12. Mostrar estados distintos
df.select("estado").distinct().show()

# 13. Agrega√ß√µes m√∫ltiplas
df.groupBy("estado").agg({"idade": "min", "nome": "count"}).show()

# 14. Ordenar por nome
df.orderBy("nome").show()

# 15. Adicionar coluna categ√≥rica por idade
df.withColumn("faixa", expr("CASE WHEN idade < 25 THEN 'jovem' WHEN idade <= 35 THEN 'adulto' ELSE 's√™nior' END")).show()

# 16. Join interno com ele mesmo
df.alias("a").join(df.alias("b"), col("a.estado") == col("b.estado")).show()

# 17. Converter idade para string
df.withColumn("idade_str", col("idade").cast("string")).printSchema()

# 18. Verificar valores nulos
df.filter(col("nome").isNull()).show()

# 19. Preencher valores nulos
df.na.fill({"estado": "SP"}).show()

# 20. Amostragem de 50%
df.sample(0.5, seed=42).show()

# 21. Upper no estado
df.withColumn("estado_upper", upper(col("estado"))).show()

# 22. Lower no nome
df.withColumn("nome_lower", lower(col("nome"))).show()

# 23. Express√£o SQL com selectExpr
df.selectExpr("nome", "idade * 10 as pontos").show()

# 24. Uni√£o do DataFrame com ele mesmo
df.union(df).show()

# 25. Cache e contar
df.cache(); print(df.count())
```

---

# üìó Parte 2 ‚Äì 25 Exerc√≠cios com Spark SQL

```python
# 1. Selecionar todos os dados
spark.sql("SELECT * FROM pessoas").show()

# 2. Selecionar apenas os nomes
spark.sql("SELECT nome FROM pessoas").show()

# 3. Selecionar pessoas com idade > 30
spark.sql("SELECT * FROM pessoas WHERE idade > 30").show()

# 4. LIKE para nome come√ßando com 'A'
spark.sql("SELECT * FROM pessoas WHERE nome LIKE 'A%'").show()

# 5. LIKE com '%a%'
spark.sql("SELECT * FROM pessoas WHERE nome LIKE '%a%'").show()

# 6. WHERE com BETWEEN
spark.sql("SELECT * FROM pessoas WHERE idade BETWEEN 20 AND 35").show()

# 7. Agrupar por estado
spark.sql("SELECT estado, COUNT(*) FROM pessoas GROUP BY estado").show()

# 8. M√©dia de idade por estado
spark.sql("SELECT estado, AVG(idade) FROM pessoas GROUP BY estado").show()

# 9. CASE WHEN categ√≥rico
spark.sql("""
SELECT nome,
  CASE 
    WHEN idade < 25 THEN 'jovem'
    WHEN idade <= 35 THEN 'adulto'
    ELSE 's√™nior'
  END AS faixa_etaria
FROM pessoas
""").show()

# 10. Soma de idades
spark.sql("SELECT SUM(idade) FROM pessoas").show()

# 11. Contagem total
spark.sql("SELECT COUNT(*) FROM pessoas").show()

# 12. Idade m√≠nima
spark.sql("SELECT MIN(idade) FROM pessoas").show()

# 13. Idade m√°xima
spark.sql("SELECT MAX(idade) FROM pessoas").show()

# 14. Pessoas acima da m√©dia
spark.sql("""
SELECT * FROM pessoas
WHERE idade > (SELECT AVG(idade) FROM pessoas)
""").show()

# 15. Estados distintos
spark.sql("SELECT DISTINCT estado FROM pessoas").show()

# 16. Nome em mai√∫sculas
spark.sql("SELECT UPPER(nome) as nome_maiusculo FROM pessoas").show()

# 17. Estado em min√∫sculas
spark.sql("SELECT LOWER(estado) as estado_minusculo FROM pessoas").show()

# 18. Idade multiplicada por 2
spark.sql("SELECT nome, idade * 2 as idade_dobrada FROM pessoas").show()

# 19. Filtro com IN
spark.sql("SELECT * FROM pessoas WHERE estado IN ('SP', 'RJ')").show()

# 20. Ordenar por estado e idade desc
spark.sql("SELECT * FROM pessoas ORDER BY estado, idade DESC").show()

# 21. Agrupar e HAVING > 1
spark.sql("""
SELECT estado, COUNT(*) as total
FROM pessoas
GROUP BY estado
HAVING total > 1
""").show()

# 22. Filtro OR
spark.sql("SELECT * FROM pessoas WHERE nome = 'Ana' OR idade < 25").show()

# 23. Agrupamento + ordena√ß√£o
spark.sql("""
SELECT estado, COUNT(*) as qtd
FROM pessoas
GROUP BY estado
ORDER BY qtd DESC
""").show()

# 24. CASE avan√ßado
spark.sql("""
SELECT nome,
  CASE
    WHEN idade < 25 THEN 'Jovem'
    WHEN idade <= 35 THEN 'Adulto'
    ELSE 'S√™nior'
  END AS faixa
FROM pessoas
""").show()

# 25. Subquery com faixa
spark.sql("""
SELECT * FROM (
  SELECT nome, idade,
    CASE
      WHEN idade < 25 THEN 'Jovem'
      WHEN idade <= 35 THEN 'Adulto'
      ELSE 'S√™nior'
    END AS faixa
  FROM pessoas
) WHERE faixa = 'Adulto'
""").show()
```

---

## ‚úÖ Conclus√£o

Voc√™ agora tem 50 exerc√≠cios **completamente resolvidos**, comentados e prontos para estudo, pr√°tica ou entrevistas t√©cnicas. Essa base cobre desde opera√ß√µes simples at√© transforma√ß√µes complexas com **Spark SQL** e **PySpark DataFrame API**.
